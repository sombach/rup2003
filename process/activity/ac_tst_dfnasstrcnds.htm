<!-- RPW META DATA START --

 
 
-- RPW META DATA END -->

<html>

<head>
<link rel="StyleSheet" href="../../rop.css" type="text/css">
<title>Activity:&nbsp;Define Assessment and Traceability Needs</title>
<meta http-equiv="Content-Type" content="text/html; charset=iso-8859-1">
</head>

<body>

 
<table border="0" cellpadding="0" cellspacing="0" width="100%"><tr><td valign="top">

<script language="JavaScript">
<!--

//Tell the TreePath to update itself
var thePath = "";
var type = typeof parent.ory_button;
if (type != "undefined") {
	 type = typeof parent.ory_button.getTreePath();
	 if (type != "undefined") {
	 	 thePath = parent.ory_button.getTreePath();
	 }
}
document.write(thePath);
-->
</script>

 


<h2 class="banner"><a name="Top"></a>Activity:&nbsp;<rpw name="PresentationName">Define Assessment and Traceability Needs</rpw><a name="XE_test__defining_assessment_of"></a><a name="XE_test__defining_traceability"></a><a name="XE_test__defining_coverage"></a></h2>

<div align="left">
<table border="1" width="85%" cellspacing="0" cellpadding="4" style="border: 1px solid rgb(128,128,128)" bordercolorlight="#808080" bordercolordark="#808080">
 <tbody valign="top">
  <tr>
      <td colspan="2"><b>Purpose</b> 
        <ul>
          <li>To define the assessment strategy for the test effort</li>
          <li>To define traceability and coverage requirements</li>
        </ul>
    </td>
  </tr>
    <tr> 
      <td colspan="2"><b>Steps</b> 
        <ul>
          <li><a href="#IdentifyAssessmentTraceRequirements">Identify assessment 
            and traceability requirements</a></li>
          <li><a href="#ConsiderConstraints">Consider constraints</a></li>
          <li><a href="#ConsiderPossibleStrategies">Consider possible strategies</a></li>
          <li><a href="#DiscussPossibleStrategies">Discuss possible strategies 
            with stakeholders</a></li>
          <li><a href="#DefineAgreeAssessmentStrategy">Define and agree on the assessment 
            strategy</a></li>
          <li><a href="#DefineToolRequirements">Define tool requirements</a></li>
          <li><a href="#EvaluateResults">Evaluate and verify your results</a></li>
        </ul>
      </td>
  </tr>
    <!-- Input_Output Artifact Begin -->
    <tr>
      <td width="50%"><b>Input Artifacts:&nbsp;</b> 
        <ul>
<li><a href="../artifact/ar_cmpln.htm">Configuration Management Plan</a></li>
<li><a href="../artifact/ar_itpln.htm">Iteration Plan</a></li>
<li><a href="../artifact/ar_qapl.htm">Quality Assurance Plan</a></li>
<li><a href="../artifact/ar_ratgl.htm">Requirements Management Plan</a></li>
<li><a href="../artifact/ar_sdp.htm">Software Development Plan</a></li>
<li><a href="../artifact/ar_tstpl.htm">Test Plan</a></li>
</ul>
&nbsp;</td>
      <td width="50%"><b>Resulting Artifacts:&nbsp;</b> 
        <ul>
<li><a href="../artifact/ar_tstpl.htm">Test Plan</a></li>
</ul>
&nbsp;</td>
    </tr>
    <!-- Input_Output Artifact End -->
    <!-- Activity Frequency -->
    <tr> 
      <td colspan="2"><b>Frequency:&nbsp;</b> This 
        activity is typically conducted multiple times per iteration. .&nbsp;</td>
    </tr>
    <!-- Activity Responsible Role -->
    <tr>
      <td colspan="2"><b>Role:&nbsp;</b> 
	    <a href="../workers/wk_tstanl.htm">Test Analyst</a>&nbsp;</td>
    </tr>
    <!-- Activity Tool Mentors -->
    <tr> 
      <td colspan="2"><b>Tool Mentors:&nbsp;</b> 
        <ul>
<li><a href="../../toolment/reqpro/tm_mgdep.htm">Managing Dependencies Using Rational RequisitePro</a></li>
<li><a href="../../toolment/testmgr/tm_tstmn.htm">Performing Test Activities Using Rational TestManager</a></li>
</ul>
&nbsp;</td>
    </tr>
    <!-- Activity More Information -->
    
  </tbody> 
</table>
<P></P>
<!-- Linked to Workflow Begin -->
<table border="1" width="85%" cellspacing="0" cellpadding="4" style="border: 1px solid rgb(128,128,128)" bordercolorlight="#808080" bordercolordark="#808080">
  <tbody valign="top">
    <tr>
      <td colspan="2"><b>Workflow Details:&nbsp;</b> 
        <ul>
<li><a href="../workflow/ovu_test.htm">Test</a>
<ul>
<li><a href="../workflow/test/wfs_imptstast.htm">Improve Test Assets</a></li>
<li><a href="../workflow/test/wfs_dfnevlmsn.htm">Define Evaluation Mission</a></li>
</ul>
</li>
</ul>
&nbsp;</td>
    </tr>
  </tbody>
</table>
<!-- Linked to Workflow End -->
</div>


<h3><a name="IdentifyAssessmentTraceRequirements">Identify assessment and traceability 
  requirements</a> <a href="#Top"><img src="../../images/top.gif"alt="To top of page" border="0" width="26" height="20"></a></h3> 

<div align="left">
<table border="1" width="92%" cellspacing="0" cellpadding="4" style="border: 1px solid rgb(128,128,128)" bordercolorlight="#808080" bordercolordark="#808080">
  <tbody valign="middle">
    <tr>
      <td width="5%"><b>Purpose:</b>&nbsp;</td>
      <td width="95%">To understand the deliverables for the software assessment 
        process and elicit the associated requirements.&nbsp;</td>
    </tr>
  </tbody>
</table>
<br>
</div>

<p>Review the Iteration Plan and identify specific assessment needs for this forthcoming 
  body of work. Ask stakeholders what they require from both assessment and traceability.</p>
<p>Also, consider whether the test effort will be formally audited either during 
  or at the conclusion of the testing effort. Formal audit requirements may necessitate 
  the retention of additional documentation and records as proof that sufficient 
  testing has been undertaken.</p>


<h3><a name="ConsiderConstraints">Consider constraints</a>
<a href="#Top"><img src="../../images/top.gif"alt="To top of page" border="0" width="26" height="20"></a></h3> 

<div align="left">
<table border="1" width="92%" cellspacing="0" cellpadding="4" style="border: 1px solid rgb(128,128,128)" bordercolorlight="#808080" bordercolordark="#808080">
  <tbody valign="middle">
    <tr>
      <td width="5%"><b>Purpose:</b>&nbsp;</td>
        
      <td width="95%">To identify the constraints that will effect the ability 
        (or the necessity) to implement the requirements.&nbsp;</td>
     </tr>
   </tbody>
</table>
<br>
</div>

<p>While there is typically a unending list of &quot;wants&quot; you might be 
  tempted to consider as requirements for traceability and assessment strategies, 
  it's important to focus on the most important &quot;needs&quot; that a) Provide 
  essential information to the project team and b) Can actually be tracked and 
  measured. It is unlikely that you will have enough resource available for your 
  strategy to cater for more than what is essentially needed.</p>

<p><b>Sub-topics:</b></p>
<ul>
  <li><a href="#ConsiderQualityLevel">Acceptable quality level</a></li>
  <li><a href="#ConsiderEnablers">Process and tool enablement</a></li>
</ul>

<h4><a name="ConsiderQualityLevel">Acceptable quality level</a>
  <a href="#ConsiderConstraints"><img src="../../images/top.gif" alt="To top of page" border="0" width="20" height="15"></a></h4> 
<p>It's important to identify what level of quality will be considered "good enough", 
  and develop an appropriate assessment strategy. Note that often quality dimensions 
  wax and wane in importance and quality levels rise and fall in the eyes of the 
  stakeholders throughout the project lifecycle</p>
<p>Review the QA Plan, Software Development Plan and interview the important stakeholders 
  themselves directly to determine what they consider will be an acceptable quality 
  level.</p>

<h4><a name="ConsiderEnablers">Process and tool enablement</a>
  <a href="#ConsiderConstraints"><img src="../../images/top.gif" alt="To top of page" border="0" width="20" height="15"></a></h4> 
<p>While you can probably imagine a world of effortless traceability and assessment 
  at a low-level of granularity, the reality is that it's difficult and usually 
  uneconomic to implement such approaches. With sophisticated tool support, it 
  can still be difficult and time-consuming to manage low-level approaches to 
  traceability; without supporting tools, almost impossible. The software engineering 
  process itself may place constraints on traceability: for example, if traceability 
  from tests to motivating requirements is desired, but the requirements themselves 
  are not being carefully managed, it may be impossible to implement this traceability.</p>
<p>Consider the constraints and limitations of both your software engineering 
  process and tools, and choose an appropriate, workable traceability and assessment 
  approach accordingly.</p>


<h3><a name="ConsiderPossibleStrategies">Consider possible strategies</a> 
<a href="#Top"><img src="../../images/top.gif"alt="To top of page" border="0" width="26" height="20"></a></h3> 

<div align="left">
<table border="1" width="92%" cellspacing="0" cellpadding="4" style="border: 1px solid rgb(128,128,128)" bordercolorlight="#808080" bordercolordark="#808080">
  <tbody valign="middle">
    <tr>
      <td width="5%"><b>Purpose:</b>&nbsp;</td>
        
      <td width="95%">To identify and outline one or more strategies that will 
        facilitate the required assessment process. &nbsp;</td>
     </tr>
   </tbody>
</table>
<br>
</div>

<p>Now that you have a better understanding of the assessment and traceability 
  requirements, and of the constraints placed on them by the desired quality level 
  and available process and tool support, you need to consider the potential assessment 
  or evaluation strategies you could employ. For a more detailed treatment of 
  possible startegies, we suggest you read Cem Kaner's paper 
  &quot;<a href="http://www.kaner.com/pdfs/pnsqc00.pdf" target="_blank"><i>Measurement 
  of the Extent of Testing</i></a>&quot;, October 2000.</p>

<p><b>Sub-topics:</b></p>
<ul>
  <li><a href="#TestCoverageStrategy">Test Coverage Analysis</a></li>
  <li><a href="#ResultsStrategy">Test Results Analysis</a></li>
  <li><a href="#DefectStrategy">Defect Analysis</a></li>
</ul>

<h4><a name="TestCoverageStrategy">Test Coverage Analysis</a>
  <a href="#ConsiderPossibleStrategies"><img src="../../images/top.gif" alt="To top of page" border="0" width="20" height="15"></a></h4> 
<p>There are many different approaches to test coverage, and no one coverage measure 
  alone provides all the coverage information necessary to form an assessment 
  of the extent or completeness of the test effort. Note that different coverage 
  strategies take more or less effort to implement, and with any particular measurement 
  category, there will usually be a depth of coverage analysis at which point 
  it becomes uneconomic to record more detailed information.</p>
<p>Some categories of test coverage measurement include: Requirements, Source 
  Code, Product Claims and Standards. We recommend you consider incorporating 
  more than one coverage caegory in your test assessment strategy. In most cases, 
  test coverage refers to the planning and implementation of specific tests in 
  the first instance. However, test coverage metrics and their analysis are also 
  useful to consider in conjunction with test results or defect analysis.</p>

<h4><a name="ResultsStrategy">Test Results Analysis</a>
  <a href="#ConsiderPossibleStrategies"><img src="../../images/top.gif" alt="To top of page" border="0" width="20" height="15"></a></h4> 
<p>A common approach to test results analysis is to simply refer to the number 
  of results that were positive or negative as a percentage of the total number 
  of tests run. Our opinion, and the opinion of other practitioner in the test 
  community, is that this is a simplistic and incomplete approach to analyzing 
  test results.</p>
<p>Instead, we recommend you analyze your test results in terms of relative trend 
  over time, and within each test cycles, consider the relative distribution of 
  test failures across different dimensions such as the functional area being 
  tested, the type of quality risks being explored, the relative complexity of 
  the tests and the test resources applied to each functional area. This information 
</p>

<h4><a name="DefectStrategy">Defect Analysis</a>
  <a href="#ConsiderPossibleStrategies"><img src="../../images/top.gif" alt="To top of page" border="0" width="20" height="15"></a></h4> 
<p>While defects themselves are obviously related to the results of the test effort, 
  the analysis of defect data does not provide any useful information about the 
  progress of the test effort or the completeness or thoroughness of that effort. 
  However, a mistake made by some test teams and project managers is to use the 
  current defect count to measure the progress of testing or as a gauge to the 
  quality of the developed software. Our opinion, and the opinion of other practitioner 
  in the test community, is that this is a meaningless approach.</p>
<p>Instead, we recommend you analyze the relative trend of the defect count over 
  time to provide a measure of relative stability. For example, assuming the test 
  effort remains relatively constant, you would typically expect to see the new 
  defect discovery rate as measured against a regular time period &quot;bell curve&quot; 
  over the course of the iteration; an increasing discovery rate that peaks then 
  tails off toward the end of the iteration. However, you'll need to provide this 
  information in conjunction with an analysis of other defect metrics such as: 
  defect resolutions rates, including an analysis of the resolution type; distribution 
  of defects by severity; distribution of defects by functional area.</p>
<p>With sophisticated tool support, you can perform complex analysis of defect 
  data relatively easily; without appropriate tool support it is a much more difficult 
  proposition.</p>


<h3><a name="DiscussPossibleStrategies">Discuss possible strategies with stakeholders</a> 
  <a href="#Top"><img src="../../images/top.gif"alt="To top of page" border="0" width="26" height="20"></a></h3> 

<div align="left">
<table border="1" width="92%" cellspacing="0" cellpadding="4" style="border: 1px solid rgb(128,128,128)" bordercolorlight="#808080" bordercolordark="#808080">
  <tbody valign="middle">
    <tr>
      <td width="5%"><b>Purpose:</b>&nbsp;</td>
        
      <td width="95%">To gather feedback through initial stakeholder review and 
        adjust the strategies as necessary.&nbsp;</td>
     </tr>
   </tbody>
</table>
<br>
</div>

<p>Present the possible strategies to the various stakeholders. Typically you'd 
  expect this to include a group made up from the following roles; Project Manager, 
  the Software Architect, the Development Manager, the System Analyst, the Configuration 
  &amp; Change Manager, the Deployment Manager and the Customer Representative. 
  Each of these roles has a stakeholding in how quality is assessed.</p>
<p>Depending on the culture of the project, you should choose an appropriate format 
  to present the possible strategies. This may range from one or more informal 
  meetings to a formal presentation or workshop session.</p>


<h3><a name="DefineAgreeAssessmentStrategy">Define and agree on the assessment 
  strategy</a> <a href="#Top"><img src="../../images/top.gif"alt="To top of page" border="0" width="26" height="20"></a></h3> 

<div align="left">
<table border="1" width="92%" cellspacing="0" cellpadding="4" style="border: 1px solid rgb(128,128,128)" bordercolorlight="#808080" bordercolordark="#808080">
  <tbody valign="middle">
    <tr>
      <td width="5%"><b>Purpose:</b>&nbsp;</td>
        
      <td width="95%">To gain stakeholder agreement on the strategy that will 
        be used.&nbsp;</td>
     </tr>
   </tbody>
</table>
<br>
</div>

<p>Take the feedback your recieve from the discussions and refibe the assessment 
  strategy to a single strategy that addresses the needs of all stakeholders.</p>
<p>Present the assessment strategy for final agreement and approval. </p>


<h3><a name="DefineToolRequirements">Define tool requirements</a> 
<a href="#Top"><img src="../../images/top.gif"alt="To top of page" border="0" width="26" height="20"></a></h3> 

<div align="left">
<table border="1" width="92%" cellspacing="0" cellpadding="4" style="border: 1px solid rgb(128,128,128)" bordercolorlight="#808080" bordercolordark="#808080">
  <tbody valign="middle">
    <tr>
      <td width="5%"><b>Purpose:</b>&nbsp;</td>
        
      <td width="95%">To define the supporting tool configuration requirements 
        that will enable the assessment process.&nbsp;</td>
     </tr>
   </tbody>
</table>
<br>
</div>

<p>As mentioned previously, with sophisticated tool support you can perform complex 
  analysis of measurement data relatively easily; without appropriate tool support 
  it is a much more difficult proposition.</p>
<p> For the following categories, consider what tool support you will need: Coverage 
  and Traceability, Defect Analysis. </p>


<h3><a name="EvaluateResults">Evaluate and verify your results</a> <a href="#Top"><img src="../../images/top.gif"alt="To top of page" border="0" width="26" height="20"></a></h3> 

<div align="left">
<table border="1" width="92%" cellspacing="0" cellpadding="4" style="border: 1px solid rgb(128,128,128)" bordercolorlight="#808080" bordercolordark="#808080">
  <tbody valign="middle">
    <tr>
      <td width="5%"><b>Purpose:</b>&nbsp;</td>
        
      <td width="95%">To verify that the activity has been completed appropriately 
        and that the resulting artifacts are acceptable.&nbsp;</td>
     </tr>
   </tbody>
</table>
<br>
</div>

<p>Now that you have completed the work, it is beneficial to verify that the work 
  was of sufficient value, and that you did not simply consume vast quantities 
  of paper. You should evaluate whether your work is of appropriate quality, and 
  that it is complete enough to be useful to those team members who will make 
  subsequent use of it as input to their work. Where possible, use the checklists 
  provided in RUP to verify that quality and completeness are &quot;good enough&quot;.</p>
<p>Have the people performing the downstream activities that rely on your work 
  as input take part in reviewing your interim work. Do this while you still have 
  time available to take action to address their concerns. You should also evaluate 
  your work against the key input artifacts to make sure you have represented 
  them accurately and sufficiently. It may be useful to have the author of the 
  input artifact review your work on this basis.</p>
<p>Try to remember that that RUP is an iterative process and that in many cases 
  artifacts evolve over time. As such, it is not usually necessary&#151;and is 
  often counterproductive&#151;to fully-form an artifact that will only be partially 
  used or will not be used at all in immediately subsequent work. This is because 
  there is a high probability that the situation surrounding the artifact will 
  change&#151;and the assumptions made when the artifact was created proven incorrect&#151;before 
  the artifact is used, resulting in wasted effort and costly rework. Also avoid 
  the trap of spending too many cycles on presentation to the detriment of content 
  value. In project environments where presentation has importance and economic 
  value as a project deliverable, you might want to consider using an administrative 
  resource to perform presentation tasks.</p>
<br>
<br>


 

<p>
 <font face="Arial"><a href="../../copyrite/copyrite.htm">
 <font size="-2">Copyright&nbsp;&copy;&nbsp;1987 - 2003 Rational Software Corporation</font>
 </a></font>
</p>


</td><td valign="top" width="24"></td><td valign="top" width="1%">
<p>
<a href="../../index.htm"></a>
</p>

<script language="JavaScript">
<!--

function loadTop()
{
  if(parent.frames.length!=0 && parent.frames[1].name=="ory_toc")
  {
     alert("The Rational Unified Process is already displayed using frames");
  }
  else
  {
    var expires = new Date();
    expires.setTime (expires.getTime() + (1000 * 20));
    document.cookie = "rup_ory_doc=" + escape (document.URL) +
    "; expires=" + expires.toUTCString() +  "; path=/";

    var new_ory_doc_loc = null;

    for(i=document.links.length-1;i>=0;i--)
    {
       if(document.links[i].href.indexOf("index.htm")!=-1)
       {
         new_ory_doc_loc = document.links[i].href;
         break;
       }
    }

    if(new_ory_doc_loc!=null)
    {
	if( self.name == "ory_doc" )
	{
		window.close();
		window.open( new_ory_doc_loc );		
	}
	else
	{
	       	top.location = new_ory_doc_loc;
	}
    }
   }
}
// -->
</script>
<script language="JavaScript">
<!--
  function getImageUrl(image)
  {
    var new_ory_doc_loc=null;
    for(i=document.links.length-1;i>=0;i--)
    {
       if(document.links[i].href.indexOf("index.htm")!=-1)
       {
         new_ory_doc_loc = document.links[i].href.substring(0,document.links[i].href.lastIndexOf("/"));
         new_ory_doc_loc = new_ory_doc_loc + "" + image;
         return new_ory_doc_loc;
       }
    }
    return null;
  }
// -->
</script>
<script
language="JavaScript">
<!--
MSFPhover =
(((navigator.appName == "Netscape") &&
  (parseInt(navigator.appVersion) >= 3 )) ||
  ((navigator.appName == "Microsoft Internet Explorer") &&
  (parseInt(navigator.appVersion) >= 4 )));

  function MSFPpreload(img)
  {
     var a=new Image();
     a.src=img;
     return a;
  }
// -->
</script>
<script language="JavaScript">
<!--
    if(MSFPhover)
    {
        RupGray=MSFPpreload(getImageUrl('/images/rup1.gif'));
        RupBlue=MSFPpreload(getImageUrl('/images/rup1_a.gif'));
    }
// -->

//new code to display the load button or not
var ory_toc_exist = typeof parent.ory_toc;
if (ory_toc_exist == "undefined") {
	document.write("<a href=\"JavaScript:loadTop();\" onmouseover=\"if(MSFPhover) document['Home'].src=RupBlue.src; self.status='Display Rational Unified Process using frames'; return true\" onmouseout=\"if(MSFPhover) document['Home'].src=RupGray.src; self.status= ' ';return true\"> <br> <img src=\"../../images/rup1.gif");
	document.write("\"  border=\"0\" alt=\Display Rational Unified Process using frames\" name=\"Home\" width=\"26\" height=\"167\"></a>");
}
else {
	document.write("&nbsp;");
}

</script>
</td></tr></table><table border="0" cellpadding="0" cellspacing="0" width="100%"><tr><td>
<p align="right"><font face="Arial"><small><small>Rational Unified
Process&nbsp;&nbsp; 
<img border="0" width="63" height="7" src="../../images/rupversion.gif">
</small></small></font>
</td></tr></table>
 

</body>

</html>